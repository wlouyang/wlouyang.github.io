<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- saved from url=(0022)https://wlouyang.github.io/ -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Wanli Ouyang - Homepage</title>

  
  <script type="text/javascript" src="jsript.js"></script>  

  <style type="text/css">@import url( style.css );
DIV.b-mobile {
    DISPLAY: none
}
  </style>

  <meta name="GENERATOR" content="MSHTML 8.00.6001.18852">
</head>

<body style="VERTICAL-ALIGN: middle">
  <table border="0" cellspacing="0" cellpadding="0" width="100%">
    <tbody>
      <tr>
	<td><a name="Top"></a>
	  <center>
	    <!--================================Begin of Header of Windows Body====================================-->
	    <table style="BACKGROUND-IMAGE: url(wave.jpg); BACKGROUND-REPEAT: no-repeat;BACKGROUND-POSITION:center" border="0" cellspacing="0" cellpadding="0" width="100%">
              <tbody>
		<tr>
		  <td>
		    <center>
		      <table style="TEXT-ALIGN: left; WIDTH: 900px" border="0" cellspacing="0" cellpadding="0">
			<tbody>
			  <tr>
			    <td class="item"><a href="#Top">Home</a></td>
			    <td class="item" style="WIDTH: 40px"></td>
			    <td class="item"><a href="#Biography">Biography</a></td>
			    <td class="item" style="WIDTH: 40px"></td>
			    <td class="item"><a href="#Education">Education</a></td>
			    <td class="item" style="WIDTH: 40px"></td>
			    <td class="item"><a href="#Research">Research</a></td>
			    <td class="item" style="WIDTH: 40px"></td>
			    <!--                <td class="item"><a href="http://www.h265.net/" target="_blank">Blog</a></td>  -->
			    <td style="WIDTH: 540px"></td></tr>
			  <tr><td style="HEIGHT: 30px;WIDTH: 900px" colspan="12"></td></tr></tbody></table></center>
            </td></tr></tbody></table>
	    <!--================================End of Header of Windows Body====================================-->

	    <!--================================Begin of Body of Windows Body====================================-->
            <table id="main" border="0" cellspacing="0" cellpadding="0" width="900">
              <tbody>
		<tr>
                  <td style="BACKGROUND-COLOR: #fcfcfc; WIDTH: 100%; OVERFLOW: hidden" valign="top">
                    
                    <div id="divContentHome" class="content_div_block">
                      <table class="garde_table_photo" align="center" border="0">
			<tbody>
			  <tr>
			    <td style="width:412px;height:200px;background-color: #FFFFFF; font-family:garamond; font-size:13px; padding: 10px 20px 10px 20px ; border: 1px solid #D2D2D2;">
                      	      <table>
				<tbody><tr>
				    <td colspan="2" style="width:165px; height:44px;"><a href="https://sydney.edu.au" target="_blank"><img src="Resources/Icons/usyd-icon.png" height="120px"></a></td>								
				    <!--								<td colspan="2" style="width:412px; height:44px;"><img src="cu-hk-university.jpg" alt="CUHK" width="308px" height="70px"></td> -->
				  </tr>
				  <tr>
				    <td colspan="2" style="width:412px; height:20px;"></td>
				  </tr>
				  <tr>
				    <td colspan="2" style="width:412px; height:22px;"><b style="font-family:garamond; font-size: 19px;font-weight: bold;">Wanli Ouyang, Ph.D, IEEE Senior Member.</b></td>
				  </tr>
				  <tr>
				    <td colspan="2" style="width:412px; height:22px;"> <b style="font-family:garamond; font-size: 15px;">Senior Lecturer at the University of Sydney</b></td>
				  </tr>
				  <tr>
				    <td colspan="2" style="width:412px; height:22px;"> <b style="font-family:garamond; font-size: 15px;">I'm with <a class="aLink" href="http://mmlab.ie.cuhk.edu.hk/" target="_blank"><i> MMlab </i></a> and <a class="aLink" href="https://sigmalab-usyd.github.io/" target="_blank"><i> SIGMA lab</i></a> </b></td>
				  </tr>
			      </tbody></table>
			      <table cellspacing="0" cellpadding="0" border="0" width="100%">
				<tbody><tr>
				    <td bgcolor="#0099FF"><img src="transparent.gif" alt="" width="1" height="1" border="0"></td>
				  </tr>
			      </tbody></table>
			      <table>
				<tbody><tr>
				    <td style="width:210px; height:44px; line-height:125%; ">
				      <a class="aLink" href="https://sigmalab-usyd.github.io/" target="_blank"> SIGMA lab</a>, <a class="aLink" href="https://sydney.edu.au/engineering/about/school-of-electrical-and-information-engineering.html" target="_blank"> School of Electrical and Information Engineering, </a> <br>
				      <a class="aLink" href="https://sydney.edu.au/" target="_blank"> The University of Sydney, </a> <br>
				      Sydney, Australia<br>
				    </td>
				    <td style="width:182px; height:44px; line-height:125%; text-align:left;">
				      <br>
				      <br>
				      <!-- <img src="mainpa1.gif" alt="CUHK" width="80px" height="12px">sydney.edu.au<br> -->
				      wanli.ouyang@sydney.edu.au
				    </td>
				  </tr>
			      </tbody></table>
			      <!--						<table>
										<tbody><tr>
										    <td colspan="2" style=" line-height:50%; text-align:center;VERTICAL-ALIGN:middle; width:356px; height:10px;">www.interdigital.com</td>
										  </tr> 
										</tbody>
			      </table>-->
			    </td>
			    <td width="150px"></td>
			    <td style="VERTICAL-ALIGN: middle; width:120px"><img alt="Photo" src="Wanli-New.jpg" width="180px" height="200px"></td>
			    <td width="167px"></td>
			  </tr>
			</tbody>
                      </table>
		    </div>
                    <div id="divContentBiography" class="content_div_block"><a name="Biography"></a>
                      <h1>Biography</h1>
                      <p class="garde_p">
                  	Wanli Ouyang obtained Ph.D from <a class="aLink" href="http://www.ee.cuhk.edu.hk/" target="_blank">  the Dept. of Electronic Engineering </a>, 
                  	the Chinese University of Hong Kong. 
                  	He is now a Senior Lecturer (equivalent to associate professor in US university systems) at the University of Sydney.
                  	His research interests include deep learning and its application to computer vision and pattern recognition, image and video processing.  <br><br> 

			<!-- Dr. Dong received the B.Eng. and M.Eng. degrees, both in Information Engineering from 
			     <a class="aLink" href="http://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a>, Hangzhou, China, 
			     in 2002 and 2005, respectively, and received the Ph.D. degree in Electronic Engineering in 2009, from 
			     <a class="aLink" href="http://www.cuhk.edu.hk/english/" target="_blank">the Chinese University of Hong Kong</a>, 
			     Hong Kong, China, where she worked as a Postdoctoral Fellow in the following year. In 2011,
			     she joined the CTO Office of 
			     <a class="aLink" href="http://www.interdigital.com/" target="_blank">InterDigital Communications</a>, U.S.A.,
			     as Staff Engineer. From 2003 to 2009, she was an active participant in Chinese standardization for 
			     multimedia with successful submissions to 
			     <a class="aLink" href="http://www.avs.org.cn/english/" target="_blank">AVS workgroup</a>. She has been engaged in 
			     HEVC standardization effort since 2011. 
			     Her research interests include high efficiency video coding and real-time video processing.<br><br> -->
			     <a target="_blank" class="aLink" href="./CV_WanliOuyang_CUHK.pdf"><img src="Resources/Icons/pdf-icon.png" width="15px" height="15px" alt="CV PDF" border="0"> Download Wanli Ouyang's Full CV</a>
			     &nbsp;&nbsp;&nbsp;&nbsp;
			     <a target="_blank" class="aLink" href="http://hk.linkedin.com/pub/wanli-ouyang/24/61b/293">
			       <img src="Resources/Icons/linkedin-icon.png" width="15px" height="15px" alt="View Wani Ouyang&#39;s LinkedIn Profile" border="0">View Wanli Ouyang's LinkedIn Profile</a> 
			     &nbsp;&nbsp;&nbsp;&nbsp;
			     <a target="_blank" class="aLink" href="http://scholar.google.com/citations?user=pw_0Z_UAAAAJ&amp hl=en">
			       <img src="Resources/Icons/google-icon.png" width="15px" height="15px" alt="View Wani Ouyang&#39;s Google Scholar Citations" border="0"> View Wanli Ouyang's Google Scholar Citations</a><br><br>
			     <a class="aLink" href="./#Top">Back To Top</a> <br><br> </p>
		    </div>
                    <h1>Information for potential Postdoctoral Fellow, Master and Ph.D. students and Final Year Program students </h1>                   
                    I moved  <a href="http://sydney.edu.au/engineering/electrical/"> the School of Electrical and Information Engineering, University of Sydney </a> as senior lecturer on 2017. 
                    If you are interested in my research topic and this university, please feel free to contact me <strong> after reading the information available <a href="https://sigmalab-usyd.github.io/recruitment/"> here</a> </strong>.
                    <h1>News </h1>                   
		    International Journal of Computer Vision (IJCV) <strong><a href="http://www.ee.oulu.fi/~lili/IJCVSIEVR2018.htm">Special Issue on Efficient Visual Recognition </a></strong>. Due date for submission of full papers: February 15, 2019.
		    <br>	<br>
		    
                    <h1>Talks </h1>
		    <a href="./talk/Wanli_AutoML.pdf"> My recent talk on 'From Manual Design to Automatic Deep Learning'</a>
		    <br> <br>
		    <a href="./talk/Tutorial_2019_China_PRCV_out.pdf"> My recent tutorial on 'Deep learning in object detection' at PRCV 2019 </a>
		    <br> <br>
		    <a href="./talk/Talk2019_China_Jan_4_out.pdf">  My recent talk on ‘Structured deep learning for visual localization and recognition’  </a>
		    <br> <br>

		    <a href="./talk/ACCV18_3D_scene_understanding.pdf">  My talk ‘Modeling deep structures for 3D scene understanding’ at ACCV 2018 workshop </a>
		    <br>	<br>

		    <a href="./talk/ACCV18_High_Performance.pdf">  My talk ‘Modeling deep structures for using high performance images’ at ACCV 2018 workshop </a>
		    <br> <br>




		    <!----																	<a href="./projects/GBD/index.html">Our team rank as #1 for object detection with provided data and external data and #1 for video object detection/tracking in the ImageNet Large Scale Visual Recognition Challenge 2016. Project page with source code </a> <br /> -->

                    <h1>Good resources on Paper Writing </h1>         
					<a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649439633&idx=1&sn=f9a6b894e4266a6e5ec4b6ec673255a2&chksm=82c0d415b5b75d03faa511eb691630d2e5d3ed2fbe3598629ab20a037b8d95bfa5c795ad1c66&mpshare=1&scene=1&srcid=1205JJGMMw3BmvYdPXJBrNyq##"> How to do good research on computer vision (Chinese) </a>
					<br>                            
					<a href="http://ec.europa.eu/eurostat/documents/64157/4374310/33-UNECE-making-data-meaningful-Part2-EN.pdf/d5b954e2-b110-469b-a2b5-78aa7c12ab62"> Making Data meaningful </a>
					<br>
                    <a href="https://www.dropbox.com/s/wgrdpmxcmb4nhl0/How%20to%20Get%20Your%20CVPR%20Paper%20Rejected.pptx?dl=0"> Slides on "How to get your paper rejected." By Prof. Ming-Hsuan Yang from UC Merced </a> <br />
					<a href="http://blog.csdn.net/daiyuchao/article/details/6419543"> Chinese blog on how to publish a top journal </a>
					<br>
					
					
					<h1>Good advices for Research Students</h1>
					<a href="https://sites.google.com/view/making-reviews-great-again/">How to write a good review?</a>
					<br>
					<a href="https://www.cc.gatech.edu/~parikh/citizenofcvpr/">How to be good CVPR reviewer? A good Area Chair? A good author? </a>
					<br>
					<a href="http://www.cs.cmu.edu/~jrs/sins.html">Three Sins of Authors in Computer Science and Math</a>
					<br>
					<a href="https://www.microsoft.com/en-us/research/academic-program/give-great-research-talk/">How to give research talk (Simon Peyton Jones, co-creator of the C-- programming language)</a>
					<br>
					<a href="https://www.microsoft.com/en-us/research/academic-program/write-great-research-paper/">How to write great research paper(Simon Peyton Jones, co-creator of the C-- programming language)</a>
					<br>
					<a href="https://www.bilibili.com/s/video/BV1df4y1m74k">How to read paper(Harry Shum)</a>
					<br>
					<a href="https://www.bilibili.com/video/BV1yt4y1Q73k?from=search&seid=13330730829523327674">如何写/审AI领域的论文 VALSE Webinar</a>
					<br>
					<a href="https://mp.weixin.qq.com/s?__biz=MzI0NTY5ODMzMQ==&mid=2247485969&idx=1&sn=0766ff7f65828486725c722c88101a07&chksm=e94bd065de3c59735e2e3876c74e646d2c87e6acdf17157cddcc7fca02afe6261fcbf88b75db&mpshare=1&scene=1&srcid=0207ALoWRslZQnzDDYaKeUNw#rd"> 研究生导师：这种学生，才是我眼中的科研好苗子！(Advice in Chinese)</a>
					<br>


		    <!--                   <a href="./projects/ImageNet/index.html">Our team rank as #1 for video object detection and #2 for still image object detection in the ImageNet Large Scale Visual Recognition Challenge 2015. Project page</a> <br />
					   <a href="./projects/ImageNet/index.html">Our team rank as #2 in the ImageNet Large Scale Visual Recognition Challenge 2014. Project page</a> <br /> -->


					   <!--========================  Recommendation on Papers  ==========================--> 
					   <div id="divContentResearch" class="content_div_block"><a name="Research"></a>
					     <h1>Chef's Recommendation on Papers </h1>

					     
					     
					     Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi, Xuesen Zhang, <strong>Wanli Ouyang</strong>, “EcoNAS: Finding Proxies for Economical Neural Architecture Search”, Proc. <em>CVPR</em>, 2020.
					     <br>  <br>

               <em> Our recent survey on object detection: </em>   <br>
					     Liu, Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and Matti Pietikäinen, "Deep learning for generic object detection: A survey,"  <em>IJCV, accepted</em>, 2019.
					     [<a class="aLink" href="https://arxiv.org/pdf/1809.02165" target="_blank">Full Text</a>]
					     <br>  <br>

					     
					     <em> A new back-bone deep model design (performs better than ResNet and DenseNet): </em>   <br>
					     Shuyang Sun, Jiangmiao Pang, Jianping Shi, Shuai Yi, <strong>Wanli Ouyang</strong>, "FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction,"  <em>NuerIPS. (Previously called NIPS)</em>, 2018.
					     [<a class="aLink" href="http://papers.nips.cc/paper/7356-fishnet-a-versatile-backbone-for-image-region-and-pixel-level-prediction.pdf" target="_blank">Full Text</a>]
					     [<a class="aLink" href="https://github.com/kevin-ssy/FishNet" target="_blank"> Source code </a>]
					     <br>  <br>

					     <em> The first end-to-end deep video compression model: </em> <br>
					     Guo Lu, <strong>Wanli Ouyang</strong>, Dong Xu, Xiaoyun Zhang, Chunlei Cai, Zhiyong Gao, "DVC: An End-to-end Deep Video Compression Framework," In Proc. CVPR 2019. 												[<a class="aLink" href="https://arxiv.org/pdf/1812.00101" target="_blank">Full Text</a>]  [<a class="aLink" href="https://github.com/GuoLusjtu/DVC" target="_blank">Source code</a>]
					     <br>  <br>

					     <em> Details on our wining entry in ImageNet 2016 challenge on object detection: </em>   <br>
                      			     Xingyu Zeng (equal contribution), <strong>Wanli Ouyang</strong> (equal contribution), Junjie Yan, Hongsheng Li, Tong Xiao, Kun Wang, Yu Liu, Yucong Zhou, Bin
					     Yang, Zhe Wang, Hui Zhou, Xiaogang Wang,
					     "Crafting GBD-Net for Object Detection," 
					     <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2017.
					     [<a class="aLink" href="./Papers/Zeng2017_GBD_PAMI.pdf" target="_blank">Full Text</a>]
					     [<a class="aLink" href="./projects/GBD/index.html" target="_blank">Project page & code </a>]												
					     [<a class="aLink" href="https://github.com/craftGBD/craftGBD" target="_blank"> Source code </a>]
					     <br>  <br>


					     <em> The first work modeling deformation in deep CNN, used for pedestrian detection: </em>   <br>
                      			     <strong>Wanli Ouyang</strong>, Hui Zhou, Hongsheng Li, Quanquan Li, Junjie Yan, Xiaogang Wang,
					     "Jointly learning deep features, deformable parts, occlusion and classification for pedestrian detection," 
					     <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, 40(8):1874-1887, 2018.
					     [<a class="aLink" href="./Papers/Ouyang2017JoingCNNPed.pdf" target="_blank">Full Text</a>]
					     [<a class="aLink" href="https://github.com/xiaohuige1/udn_extend" target="_blank">Source code</a>]                        <br>  <br>

					     <em> Extend our work on modeling deformation for generic object detection. This new deformation handling layer can be placed anywhere. </em>   <br>
					     <strong>Wanli Ouyang</strong>, Xingyu Zeng,  Xiaogang Wang, et al,
					     "DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks," 
					     <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2016.
					     [<a class="aLink" href="./Papers/DeepID-Net.pdf" target="_blank">Full Text</a>]
					     [<a class="aLink" title="Project" href="./projects/ImageNet/index.html" target="_blank">Project</a>]																								<br>  <br>
					     
					     
					     <em> The first cascade network for generic object detection. </em>   <br>
                      			     <strong>Wanli Ouyang</strong>, Kun Wang, Xin Zhu, Xiaogang Wang. "Chained Cascade Network
					     for Object Detection", <em>Proc. ICCV</em>, 2017.
					     [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Ouyang_Chained_Cascade_Network_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]  
					     [<a class="aLink" title="Download source code" href="https://github.com/wk910930/ccnn" target="_blank">Source code</a>]  	
					     <br>  
					     <br>
					     
					     <em> A simple and effective multi-scale feature operation. Showing and solving the initialization problem in existing multi-branch networks, e.g. Inception V2-V5, Hourglass, ResNxt, etc. </em>   <br>

					     Wei Yang, Shuang Li, <strong>Wanli Ouyang</strong>, Hongsheng Li, XiaogangWang. "Learning Feature Pyramids for Human Pose Estimation", <em>Proc. ICCV</em>, 2017.
					     [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Yang_Learning_Feature_Pyramids_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Code on Github" href="https://github.com/bearpaw/PyraNet" target="_blank">Source code</a>]
					     <br>  <br>



					     <em> The first work on structured feature learning. </em>   <br>
                      			     X. Chu,  <strong>Wanli Ouyang</strong> , H. Li, and X. Wang. 
                      			     "Structured feature learning for pose estimation",  In <em>Proc. CVPR </em> 2016. 
					     [<a class="aLink" title="Download Full Text" href="http://arxiv.org/pdf/1603.09065.pdf" target="_blank">Full Text</a>]
					     [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html" target="_blank">Project and dataset </a>]                          
					     [<a class="aLink" title="Project" href="https://www.youtube.com/watch?v=SMFt6TJ-ntA" target="_blank">Spotlight talk</a>]                          
					     [<a class="aLink" title="Code" href="https://github.com/chuxiaoselena/StructuredFeature" target="_blank">Source code </a>]                          
					     [<a class="aLink" title="Supplementary" href="http://www.ee.cuhk.edu.hk/~xgwang/StructureFeature/supp.pdf" target="_blank">Supplementary </a>]                          
					     <br>
					     <br>

					     <em> The first Fully Convolutional Network for visual tracking. </em> <br>
                      			     Lijun Wang,  <strong>Wanli Ouyang</strong>, Xiaogang Wang, and Huchuan Lu,
                      			     "Visual Tracking with Fully Convolutional Networks",  In <em>Proc. ICCV </em> 2015. 
					     [<a class="aLink" title="Download Full Text" href="Papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
					     [<a class="aLink" title="Project" href="http://scott89.github.io/FCNT/" target="_blank">Project and source code </a>]                

					     
					     
					     
					     
					     
					     
					     
					     <!--========================Journal Papers ========================-->                  
					     
					     <h1>Journal Papers</h1>

					     
					     
					     <table border="0" cellspacing="0" cellpadding="5" width="900">
					       <tbody id="journal_list">

						 <tr class="pub_tr_1">  
						   <td width="20%" align="left" colspan="2" style="HEIGHT:10px"></td></tr>
						 <tr class="pub_tr_1">  
						   <td width="20%" align="left" colspan="2"><a class="aLink" href="#Top">Back To Top</a></td></tr>
						 
					       </tbody>
					     </table>

					     
                      			     
					     <!--========================Conference Papers ========================-->                      	
					     <h1>Conference Papers</h1>
					     <table border="0" cellspacing="0" cellpadding="5" width="900">
					       <tbody id="conference_list">
						 
						 
						 <tr class="pub_tr_1">  
						   <td width="20%" align="left" colspan="2" style="HEIGHT:10px"></td></tr>
						 <tr class="pub_tr_1">  
						   <td width="20%" align="left" colspan="2"><a class="aLink" href="./#Top">Back To Top</a></td></tr>
					     </tbody></table>
					   </div>
					   
	    </td></tr></tbody></table>
	    <!--================================End of Body of Windows Body====================================-->
	    <!--================================Begin of Footer of Windows Body====================================-->
	    <center>
	      <table border="0" cellspacing="0" cellpadding="0" width="900px" style="BACKGROUND-IMAGE: url(footer_bg.jpg); COLOR: #2b547e">
		<tbody>
		  <tr style="VERTICAL-ALIGN: middle">
		    <!--          <td style="TEXT-ALIGN: right; WIDTH: 200px; HEIGHT: 30px">
				  <img alt="AVSX.org" src="avsx_logo_small.gif"></td> -->
		    <td class="i_td_windows_footer">
		      Last Update: Apr. 2013. Copyright © 2013-. 
		      <a href="http://validator.w3.org/check?uri=./saved_resource.htm">
			<img style="BORDER-BOTTOM: 0px; BORDER-LEFT: 0px; WIDTH: 45px; HEIGHT: 15px; BORDER-TOP: 0px; BORDER-RIGHT: 0px" alt="Valid HTML 4.01 Transitional" src="valid-html401-blue.png"></a> 
		      <a href="http://jigsaw.w3.org/css-validator/validator?uri=./saved_resource.htm">
			<img style="BORDER-BOTTOM: 0px; BORDER-LEFT: 0px; WIDTH: 45px; HEIGHT: 15px; BORDER-TOP: 0px; BORDER-RIGHT: 0px" alt="Valid CSS!" src="valid-css-blue.png"></a>
		    </td>
		  </tr>
		</tbody>
	      </table>
	    </center>
	    <!--================================End of Footer of Windows Body====================================-->
	  </center>
	</td>
      </tr>
    </tbody>
  </table>



  <script>
    // generate publication list from data.json
    "use strict"


    function readTextFile(file, callback) {
	var rawFile = new XMLHttpRequest();
	rawFile.overrideMimeType("application/json");
	rawFile.open("GET", file, false); //fase for synchronous requests
	rawFile.onreadystatechange = function() {
            if (rawFile.readyState === 4 && rawFile.status == "200") {
		callback(rawFile.responseText);
            }
	}
	rawFile.send(null);
    }
    let journal_data;
    let conference_data;
	let data_location = 'https://raw.githubusercontent.com/wlouyang/wlouyang.github.io/master/data.json'
    readTextFile(data_location, function(text){
	let data = JSON.parse(text);
	journal_data = data.journals;
	conference_data = data.conferences;
    });


    function journalPubItemConstructor(pubitem) {
      function filter_mandatory_members(value, index, arr){
        let mandatory_members = ["authors", "title", "publisher", "image"];
        return !mandatory_members.includes(value);
      }
      let all_members = Object.keys(pubitem);
      all_members = all_members.filter(filter_mandatory_members)
	let obj;
	obj = document.createElement('template');
  let additional_link_template = `[<a class="aLink" href="LINK_TO_REPLACE" >TEXT_TO_REPLACE</a>]`;
	let html_template = `
        <tr class="pub_tr_2">
          <td width="20px" class="pub_td_number"></td>
          <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="IMAGE" width="336px" height="200px"></td>
          <td width="500px" style="vertical-align: middle" class="pub_td_text">
          AUTHORS, "TITLE"  JOURNAL
          ADDITIONAL_LINKS
          <br>
          </td>
        </tr>
      `;
  let additional_links = ""
  let num_links = all_members.length
  for (let i=0; i<num_links; i++) {
    additional_links = additional_links.concat(additional_link_template
      .replace("LINK_TO_REPLACE", pubitem[all_members[i]])
      .replace("TEXT_TO_REPLACE", all_members[i]))
  }
	obj.innerHTML = html_template
	    .replace("AUTHORS", pubitem.authors)
	    .replace("TITLE", pubitem.title)
	    .replace("JOURNAL", pubitem.publisher)
	    .replace("IMAGE", pubitem.image)
      .replace("ADDITIONAL_LINKS", additional_links)
	    .replace(`<img style="width: 336Px;" alt="Wanli" src="" width="336px" height="200px">`, "");
  


	return obj.content.firstElementChild;
    }

    function conferencePubItemConstructor(pubitem) {
      function filter_mandatory_members(value, index, arr){
        let mandatory_members = ["authors", "title", "publisher"];
        return !mandatory_members.includes(value);
      }
      // let all_members = Object.keys(pubitem);
      // all_members = all_members.filter(filter_mandatory_members)
	let obj = document.createElement('template');
	let html_template = `
      <tr class="pub_tr_2">
      <td width="20px" class="pub_td_number"> </td>
      <td width="304px" style="vertical-align: middle"> MAIN_IMAGES
      </td>

      <td class="pub_td_text" width="500px" style="vertical-align: middle">
	  <h4> CONFERENCE_NAME </h4>
        PAPER_LIST
      </td>
      </tr>
      `

	let image_list = "";
	let main_image;
	for (main_image of pubitem.main_images) {
            image_list += `<img alt="" border="0" src="${main_image}" width="304px" height="200" >`
	}


	let paper_list = "";
	let paper;
  let all_members
  let additional_links
  let additional_link_template = `[<a class="aLink" href="LINK_TO_REPLACE" >TEXT_TO_REPLACE</a>]`;
	for (paper of pubitem.papers) {
    all_members = Object.keys(paper)
    all_members = all_members.filter(filter_mandatory_members)
    additional_links = ""
    let num_links = all_members.length
    for (let i=0; i<num_links; i++) {
      additional_links = additional_links.concat(additional_link_template
        .replace("LINK_TO_REPLACE", paper[all_members[i]])
        .replace("TEXT_TO_REPLACE", all_members[i]))
    }
    paper_list += `
          <br>
          ${paper.authors}, "${paper.title}", ${paper.publisher}
          ${additional_links}
          <br>
        `
	}

	obj.innerHTML = html_template
		.replace("CONFERENCE_NAME", pubitem.conference_name)
	    .replace("MAIN_IMAGES", image_list)
	    .replace("PAPER_LIST", paper_list);

	return obj.content.firstElementChild;
    }

    //Journal list generation
    let journal_list = document.getElementById("journal_list");
    let pubitem;
    for (pubitem of journal_data.reverse()) {
	journal_list.prepend(journalPubItemConstructor(pubitem))
    }

    //Conference list generation
    let conference_list = document.getElementById("conference_list");
    for (pubitem of conference_data.reverse()) {
	conference_list.prepend(conferencePubItemConstructor(pubitem))
    }



    </script>

</body>
